{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Bedrock\n",
    "from langchain.llms.bedrock import Bedrock as BedrockLLM\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "import boto3\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Bedrock client\n",
    "bedrock_runtime = boto3.client(\n",
    "    service_name='bedrock-runtime',\n",
    "    region_name='us-east-1'  # Change to your preferred region\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invoke_mistral_7b(prompt, max_tokens=512, temperature=0.9, top_p=0.9):\n",
    "    \"\"\"\n",
    "    Invokes Mistral 7B Instruct model on AWS Bedrock\n",
    "    \n",
    "    Args:\n",
    "        prompt (str): Input prompt\n",
    "        max_tokens (int): Maximum tokens to generate\n",
    "        temperature (float): Creativity control (0-1)\n",
    "        top_p (float): Nucleus sampling threshold\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated response\n",
    "    \"\"\"\n",
    "    # Format the prompt in Mistral's instruction format\n",
    "    formatted_prompt = f\"<s>[INST] {prompt} [/INST]\"\n",
    "    \n",
    "    body = {\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": top_p\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = bedrock_runtime.invoke_model(\n",
    "            body=json.dumps(body),\n",
    "            modelId=\"mistral.mistral-7b-instruct-v0:2\",\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        return response_body['outputs'][0]['text']\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chatbot_response(client, model_name, messages, temperature=0.9, max_tokens=512):\n",
    "    \"\"\"\n",
    "    Gets chatbot response from Mistral 7B on AWS Bedrock\n",
    "    \n",
    "    Args:\n",
    "        client: boto3 bedrock-runtime client\n",
    "        model_name: Model ID (e.g., \"mistral.mistral-7b-instruct-v0:2\")\n",
    "        messages: List of message dicts with \"role\" and \"content\"\n",
    "        temperature: Creativity control (0-1)\n",
    "        max_tokens: Maximum tokens to generate\n",
    "        \n",
    "    Returns:\n",
    "        str: Generated response\n",
    "    \"\"\"\n",
    "    # Format conversation history for Mistral\n",
    "    formatted_prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"system\":\n",
    "            formatted_prompt += f\"<<SYS>>\\n{message['content']}\\n<</SYS>>\\n\\n\"\n",
    "        elif message[\"role\"] == \"user\":\n",
    "            formatted_prompt += f\"<s>[INST] {message['content']} [/INST]\"\n",
    "        elif message[\"role\"] == \"assistant\":\n",
    "            formatted_prompt += f\" {message['content']} </s>\"\n",
    "    \n",
    "    body = {\n",
    "        \"prompt\": formatted_prompt,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": 0.8  # Matching your example\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = client.invoke_model(\n",
    "            body=json.dumps(body),\n",
    "            modelId=model_name,\n",
    "            accept='application/json',\n",
    "            contentType='application/json'\n",
    "        )\n",
    "        \n",
    "        response_body = json.loads(response['body'].read())\n",
    "        return response_body['outputs'][0]['text']\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error invoking model: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import boto3\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guard Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GuardAgent():\n",
    "    def __init__(self):\n",
    "        self.client = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name=os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "        )\n",
    "        self.model_name = os.getenv(\"BEDROCK_MODEL_NAME\", \"mistral.mistral-7b-instruct-v0:2\")\n",
    "\n",
    "    def get_response(self, message):\n",
    "        messages = deepcopy(message)\n",
    "\n",
    "        system_prompt = \"\"\"<<SYS>>\n",
    "        You are an helpful AI assistant for a Plant-selling store which sells plants and plant-related products.\n",
    "        Your task is to determine whether user is asking something relevant to the plant store or not.\n",
    "\n",
    "        The user is allowed to ask:\n",
    "        1. Ask questions about the plant store like location, working hours, Fertilizers, compost, plants and plant shop related question.\n",
    "        2. Make an order.\n",
    "        3. Ask about recommendations of what to buy.\n",
    "\n",
    "        The user is not allowed to ask:\n",
    "        1. Ask about anything other than the plant store.\n",
    "        2. Ask questions about the staff\n",
    "        3. Ask about the owner of the store.\n",
    "\n",
    "        Your output MUST be in this exact JSON format (no other text, no code blocks):\n",
    "\n",
    "        {\n",
    "            \"chain_of_thought\": \"Analyze which point this input relates to\",\n",
    "            \"decision\": \"allowed\" or \"not allowed\",\n",
    "            \"message\": \"Your response to the user. If 'not allowed', use exactly: 'Sorry, I can't help you with that. Can I help you with something else?'\"\n",
    "        }\n",
    "        <</SYS>>\"\"\"\n",
    "\n",
    "\n",
    "        # Prepare messages in Mistral format\n",
    "        input_messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages[-3:]\n",
    "\n",
    "        # Get response from Mistral\n",
    "        chatbot_output = get_chatbot_response(\n",
    "            client=self.client,\n",
    "            model_name=self.model_name,\n",
    "            messages=input_messages,\n",
    "            temperature=0.1  # Lower temperature for more deterministic decisions\n",
    "        )\n",
    "\n",
    "        # Clean and verify the output\n",
    "        chatbot_output = self.clean_json_output(chatbot_output)\n",
    "        output = self.postprocess(chatbot_output)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def clean_json_output(self, output):\n",
    "        \"\"\"Ensure the output is valid JSON with all required fields\"\"\"\n",
    "        try:\n",
    "            # Remove any code blocks and whitespace\n",
    "            output = output.strip().replace(\"```json\", \"\").replace(\"```\", \"\")\n",
    "            \n",
    "            # Parse JSON\n",
    "            parsed = json.loads(output)\n",
    "            \n",
    "            # Validate required fields\n",
    "            required_fields = [\"chain_of_thought\", \"decision\", \"message\"]\n",
    "            if not all(field in parsed for field in required_fields):\n",
    "                raise ValueError(\"Missing required fields in JSON output\")\n",
    "                \n",
    "            # Validate decision values\n",
    "            if parsed[\"decision\"] not in [\"allowed\", \"not allowed\"]:\n",
    "                raise ValueError(\"Invalid decision value\")\n",
    "                \n",
    "            return parsed\n",
    "            \n",
    "        except (json.JSONDecodeError, ValueError) as e:\n",
    "            return {\n",
    "                \"chain_of_thought\": f\"Invalid response: {str(e)}\",\n",
    "                \"decision\": \"not allowed\",\n",
    "                \"message\": \"Sorry, I can't help you with that. Can I help you with something else?\"\n",
    "            }\n",
    "\n",
    "    def postprocess(self, output):\n",
    "        \"\"\"\n",
    "        Postprocess the output from the chatbot to ensure it is in the desired format.\n",
    "        \"\"\"\n",
    "        if not isinstance(output, dict):\n",
    "            output = {\n",
    "                \"chain_of_thought\": \"Invalid response format\",\n",
    "                \"decision\": \"not allowed\",\n",
    "                \"message\": \"Sorry, I can't help you with that. Can I help you with something else?\"\n",
    "            }\n",
    "\n",
    "        # Ensure message is never empty for 'not allowed' decisions\n",
    "        if output.get(\"decision\", \"not allowed\") == \"not allowed\":\n",
    "            output[\"message\"] = output.get(\"message\") or \"Sorry, I can't help you with that. Can I help you with something else?\"\n",
    "\n",
    "        dict_output = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": output.get(\"message\", \"\"),\n",
    "            \"memory\": {\n",
    "                \"agent\": \"guard_agent\",\n",
    "                \"guard_decision\": output.get(\"decision\", \"not allowed\"),\n",
    "                \"chain_of_thought\": output.get(\"chain_of_thought\", \"\")\n",
    "            }\n",
    "        }\n",
    "        return dict_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationAgent():\n",
    "    def __init__(self):\n",
    "        self.client = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name=os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "        )\n",
    "        self.model_name = os.getenv(\"BEDROCK_MODEL_NAME\", \"mistral.mistral-7b-instruct-v0:2\")\n",
    "    \n",
    "    def get_response(self, messages):\n",
    "        messages = deepcopy(messages)\n",
    "\n",
    "        system_prompt = \"\"\"<<SYS>>\n",
    "You are a helpful AI assistant working for a Plant Shop application.\n",
    "\n",
    "Your main task is to decide which specialized agent should handle the user's message.  \n",
    "There are two agents you can choose from:\n",
    "\n",
    "1. **details_agent**:  \n",
    "   This agent handles questions only about:\n",
    "   - Plant shop location\n",
    "   - Plant shop working hours\n",
    "   - Plant shop history\n",
    "   - Delivery locations\n",
    "   - Product collection and inventory\n",
    "   - Prices of products\n",
    "\n",
    "2. **order_taking_agent**:  \n",
    "   This agent manages conversations where the user wants to place an order or is completing a purchase.\n",
    "\n",
    "You must output your answer in the following strict JSON format:\n",
    "\n",
    "{\n",
    "    \"chain_of_thought\": \"Explain why you chose a specific agent based on the user's message\",\n",
    "    \"decision\": \"details_agent | order_taking_agent\",\n",
    "    \"message\": \"\"\n",
    "}\n",
    "\n",
    "Important:  \n",
    "- Think carefully about the user's input before choosing the agent.  \n",
    "- Follow the JSON format exactly without adding any extra text outside of it.\n",
    "<</SYS>>\"\"\"\n",
    "        \n",
    "        # Format messages for Mistral\n",
    "        formatted_messages = [{\"role\": \"system\", \"content\": system_prompt}] + messages[-3:]\n",
    "\n",
    "        chatbot_output = get_chatbot_response(\n",
    "            client=self.client,\n",
    "            model_name=self.model_name,\n",
    "            messages=formatted_messages,\n",
    "            temperature=0.3  # Lower temperature for more consistent routing\n",
    "        )\n",
    "\n",
    "        # Clean and verify JSON output\n",
    "        chatbot_output = self.clean_json_output(chatbot_output)\n",
    "        output = self.postprocess(chatbot_output)\n",
    "        return output\n",
    "\n",
    "    def clean_json_output(self, output):\n",
    "        \"\"\"Ensure the output is valid JSON\"\"\"\n",
    "        try:\n",
    "            # Remove any markdown code blocks\n",
    "            output = output.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            return json.loads(output)\n",
    "        except json.JSONDecodeError:\n",
    "            # Fallback to details agent if parsing fails\n",
    "            return {\n",
    "                \"chain_of_thought\": \"Failed to parse response - defaulting to details agent\",\n",
    "                \"decision\": \"details_agent\",\n",
    "                \"message\": \"\"\n",
    "            }\n",
    "\n",
    "    def postprocess(self, output):\n",
    "        \"\"\"Convert to standard agent output format\"\"\"\n",
    "        if not isinstance(output, dict):\n",
    "            output = {\n",
    "                \"chain_of_thought\": \"Invalid response format\",\n",
    "                \"decision\": \"details_agent\",\n",
    "                \"message\": \"\"\n",
    "            }\n",
    "\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": output.get(\"message\", \"\"),\n",
    "            \"memory\": {\n",
    "                \"agent\": \"classification_agent\",\n",
    "                \"classification_decision\": output.get(\"decision\", \"details_agent\")\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Order Taking Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "import boto3\n",
    "from copy import deepcopy\n",
    "from dotenv import load_dotenv\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "class OrderTakingAgent():\n",
    "    def __init__(self):\n",
    "        self.client = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name=os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "        )\n",
    "        self.model_name = os.getenv(\"BEDROCK_MODEL_NAME\", \"mistral.mistral-7b-instruct-v0:2\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Complete product list in the specified format\n",
    "        self.products = [\n",
    "            {\"name\": \"White Butterfly (Syngonium Podophyllum)\", \"price\": 100},\n",
    "            {\"name\": \"Peace Lily\", \"price\": 150},\n",
    "            {\"name\": \"Chlorophytum Spider Plant\", \"price\": 100},\n",
    "            {\"name\": \"Money Plant Marble Prince\", \"price\": 150},\n",
    "            {\"name\": \"Snake Plant (Sansevieria)\", \"price\": 200},\n",
    "            {\"name\": \"Aglaonema Lipstick\", \"price\": 300},\n",
    "            {\"name\": \"Jade Plant (Portulacaria afra)\", \"price\": 200},\n",
    "            {\"name\": \"Rubber Tree (Ficus elastica)\", \"price\": 300},\n",
    "            {\"name\": \"Krishna Tulsi Plant (Black)\", \"price\": 50},\n",
    "            {\"name\": \"Lemon Grass\", \"price\": 50},\n",
    "            {\"name\": \"Curry Leaves\", \"price\": 50},\n",
    "            {\"name\": \"Rama Tulsi Plant\", \"price\": 50},\n",
    "            {\"name\": \"Ajwain Leaves\", \"price\": 100},\n",
    "            {\"name\": \"Mentha Arvensis (Japanese Mint)\", \"price\": 100},\n",
    "            {\"name\": \"Black Turmeric Plant (Black Haldi)\", \"price\": 300},\n",
    "            {\"name\": \"Bhuiamla\", \"price\": 100},\n",
    "            {\"name\": \"Wild Asparagus\", \"price\": 200},\n",
    "            {\"name\": \"Jasminum sambac\", \"price\": 150},\n",
    "            {\"name\": \"Parijat Tree\", \"price\": 300},\n",
    "            {\"name\": \"Rose\", \"price\": 100},\n",
    "            {\"name\": \"Raat Rani\", \"price\": 200},\n",
    "            {\"name\": \"Shevanti\", \"price\": 100},\n",
    "            {\"name\": \"Marigold (Orange)\", \"price\": 50},\n",
    "            {\"name\": \"Champa (White)\", \"price\": 200},\n",
    "            {\"name\": \"Rajnigandha\", \"price\": 100},\n",
    "            {\"name\": \"Fragrant Panama rose\", \"price\": 300},\n",
    "            {\"name\": \"Pincushion Cactus\", \"price\": 150},\n",
    "            {\"name\": \"Bunny Ear Cactus\", \"price\": 200},\n",
    "            {\"name\": \"Echinopsis chamaecereus\", \"price\": 250},\n",
    "            {\"name\": \"Golden Pipe Cactus\", \"price\": 300},\n",
    "            {\"name\": \"Moon Cactus (Grafted)\", \"price\": 300},\n",
    "            {\"name\": \"Graptoveria opalina\", \"price\": 250},\n",
    "            {\"name\": \"Crassula tetragona\", \"price\": 200},\n",
    "            {\"name\": \"Aloe Vera\", \"price\": 100},\n",
    "            {\"name\": \"Euphorbia (Red)\", \"price\": 300},\n",
    "            {\"name\": \"Vermicompost\", \"price\": 10, \"unit\": \"kg\"},\n",
    "            {\"name\": \"Vermicompost Mixture\", \"price\": 20, \"unit\": \"kg\"},\n",
    "            {\"name\": \"Dec-Neemo (Bio-fertilizer)\", \"price\": 150, \"unit\": \"ltr\"},\n",
    "            {\"name\": \"Dec-Mori (Bio-fertilizer)\", \"price\": 150, \"unit\": \"ltr\"},\n",
    "            {\"name\": \"Agni Shield\", \"price\": 300}\n",
    "        ]\n",
    "\n",
    "        # Add product aliases and normalization\n",
    "        self.product_aliases = self._create_product_aliases()\n",
    "        self.product_names = [p[\"name\"] for p in self.products]\n",
    "    \n",
    "    def _create_product_aliases(self):\n",
    "        return {\n",
    "            # White Butterfly (Syngonium Podophyllum)\n",
    "            \"white butterfly\": \"White Butterfly (Syngonium Podophyllum)\",\n",
    "            \"syngonium\": \"White Butterfly (Syngonium Podophyllum)\",\n",
    "            \"arrowhead plant\": \"White Butterfly (Syngonium Podophyllum)\",\n",
    "            \n",
    "            # Peace Lily\n",
    "            \"spathiphyllum\": \"Peace Lily\",\n",
    "            \"white sails\": \"Peace Lily\",\n",
    "            \"cobra plant\": \"Peace Lily\",\n",
    "            \n",
    "            # Chlorophytum Spider Plant\n",
    "            \"spider plant\": \"Chlorophytum Spider Plant\",\n",
    "            \"airplane plant\": \"Chlorophytum Spider Plant\",\n",
    "            \"ribbon plant\": \"Chlorophytum Spider Plant\",\n",
    "            \n",
    "            # Money Plant Marble Prince\n",
    "            \"money plant\": \"Money Plant Marble Prince\",\n",
    "            \"marble queen\": \"Money Plant Marble Prince\",\n",
    "            \"pothos\": \"Money Plant Marble Prince\",\n",
    "            \n",
    "            # Snake Plant (Sansevieria)\n",
    "            \"mother in law's tongue\": \"Snake Plant (Sansevieria)\",\n",
    "            \"sansevieria\": \"Snake Plant (Sansevieria)\",\n",
    "            \"viper's bowstring hemp\": \"Snake Plant (Sansevieria)\",\n",
    "            \n",
    "            # Aglaonema Lipstick\n",
    "            \"chinese evergreen\": \"Aglaonema Lipstick\",\n",
    "            \"red aglaonema\": \"Aglaonema Lipstick\",\n",
    "            \"painted drop tongue\": \"Aglaonema Lipstick\",\n",
    "            \n",
    "            # Jade Plant (Portulacaria afra)\n",
    "            \"jade tree\": \"Jade Plant (Portulacaria afra)\",\n",
    "            \"elephant bush\": \"Jade Plant (Portulacaria afra)\",\n",
    "            \"dwarf jade\": \"Jade Plant (Portulacaria afra)\",\n",
    "            \n",
    "            # Rubber Tree (Ficus elastica)\n",
    "            \"rubber plant\": \"Rubber Tree (Ficus elastica)\",\n",
    "            \"ficus\": \"Rubber Tree (Ficus elastica)\",\n",
    "            \"india rubber tree\": \"Rubber Tree (Ficus elastica)\",\n",
    "            \n",
    "            # Krishna Tulsi Plant (Black)\n",
    "            \"black tulsi\": \"Krishna Tulsi Plant (Black)\",\n",
    "            \"shyama tulsi\": \"Krishna Tulsi Plant (Black)\",\n",
    "            \"krishna holy basil\": \"Krishna Tulsi Plant (Black)\",\n",
    "            \n",
    "            # Lemon Grass\n",
    "            \"lemongrass\": \"Lemon Grass\",\n",
    "            \"citronella\": \"Lemon Grass\",\n",
    "            \"cymbopogon\": \"Lemon Grass\",\n",
    "            \n",
    "            # Curry Leaves\n",
    "            \"kadi patta\": \"Curry Leaves\",\n",
    "            \"sweet neem\": \"Curry Leaves\",\n",
    "            \"murraya\": \"Curry Leaves\",\n",
    "            \n",
    "            # Rama Tulsi Plant\n",
    "            \"green tulsi\": \"Rama Tulsi Plant\",\n",
    "            \"rama holy basil\": \"Rama Tulsi Plant\",\n",
    "            \"light holy basil\": \"Rama Tulsi Plant\",\n",
    "            \n",
    "            # Ajwain Leaves\n",
    "            \"carom leaves\": \"Ajwain Leaves\",\n",
    "            \"ajowan\": \"Ajwain Leaves\",\n",
    "            \"bishop's weed\": \"Ajwain Leaves\",\n",
    "            \n",
    "            # Mentha Arvensis (Japanese Mint)\n",
    "            \"wild mint\": \"Mentha Arvensis (Japanese Mint)\",\n",
    "            \"corn mint\": \"Mentha Arvensis (Japanese Mint)\",\n",
    "            \"field mint\": \"Mentha Arvensis (Japanese Mint)\",\n",
    "            \n",
    "            # Black Turmeric Plant (Black Haldi)\n",
    "            \"kali haldi\": \"Black Turmeric Plant (Black Haldi)\",\n",
    "            \"curcuma caesia\": \"Black Turmeric Plant (Black Haldi)\",\n",
    "            \"black zedoary\": \"Black Turmeric Plant (Black Haldi)\",\n",
    "            \n",
    "            # Bhuiamla\n",
    "            \"bhumi amla\": \"Bhuiamla\",\n",
    "            \"stonebreaker\": \"Bhuiamla\",\n",
    "            \"chanca piedra\": \"Bhuiamla\",\n",
    "            \n",
    "            # Wild Asparagus\n",
    "            \"shatavari\": \"Wild Asparagus\",\n",
    "            \"asparagus racemosus\": \"Wild Asparagus\",\n",
    "            \"indian asparagus\": \"Wild Asparagus\",\n",
    "            \n",
    "            # Jasminum sambac\n",
    "            \"arabian jasmine\": \"Jasminum sambac\",\n",
    "            \"mogra\": \"Jasminum sambac\",\n",
    "            \"sampaguita\": \"Jasminum sambac\",\n",
    "            \n",
    "            # Parijat Tree\n",
    "            \"night jasmine\": \"Parijat Tree\",\n",
    "            \"harsingar\": \"Parijat Tree\",\n",
    "            \"tree of sorrow\": \"Parijat Tree\",\n",
    "            \n",
    "            # Rose\n",
    "            \"gulab\": \"Rose\",\n",
    "            \"rosa\": \"Rose\",\n",
    "            \"flower queen\": \"Rose\",\n",
    "            \n",
    "            # Raat Rani\n",
    "            \"night blooming jasmine\": \"Raat Rani\",\n",
    "            \"cestrum\": \"Raat Rani\",\n",
    "            \"queen of night\": \"Raat Rani\",\n",
    "            \n",
    "            # Shevanti\n",
    "            \"chrysanthemum\": \"Shevanti\",\n",
    "            \"guldaudi\": \"Shevanti\",\n",
    "            \"autumn flower\": \"Shevanti\",\n",
    "            \n",
    "            # Marigold (Orange)\n",
    "            \"genda\": \"Marigold (Orange)\",\n",
    "            \"tagetes\": \"Marigold (Orange)\",\n",
    "            \"orange genda\": \"Marigold (Orange)\",\n",
    "            \n",
    "            # Champa (White)\n",
    "            \"plumeria\": \"Champa (White)\",\n",
    "            \"frangipani\": \"Champa (White)\",\n",
    "            \"white champa\": \"Champa (White)\",\n",
    "            \n",
    "            # Rajnigandha\n",
    "            \"tuberose\": \"Rajnigandha\",\n",
    "            \"polianthes\": \"Rajnigandha\",\n",
    "            \"night queen\": \"Rajnigandha\",\n",
    "            \n",
    "            # Fragrant Panama rose\n",
    "            \"panama rose\": \"Fragrant Panama rose\",\n",
    "            \"sweet rose\": \"Fragrant Panama rose\",\n",
    "            \"rondeletia\": \"Fragrant Panama rose\",\n",
    "            \n",
    "            # Pincushion Cactus\n",
    "            \"mammillaria\": \"Pincushion Cactus\",\n",
    "            \"cactus ball\": \"Pincushion Cactus\",\n",
    "            \"nipple cactus\": \"Pincushion Cactus\",\n",
    "            \n",
    "            # Bunny Ear Cactus\n",
    "            \"polka dot cactus\": \"Bunny Ear Cactus\",\n",
    "            \"angel wings\": \"Bunny Ear Cactus\",\n",
    "            \"opuntia\": \"Bunny Ear Cactus\",\n",
    "            \n",
    "            # Echinopsis chamaecereus\n",
    "            \"peanut cactus\": \"Echinopsis chamaecereus\",\n",
    "            \"chamaecereus\": \"Echinopsis chamaecereus\",\n",
    "            \"mini cactus\": \"Echinopsis chamaecereus\",\n",
    "            \n",
    "            # Golden Pipe Cactus\n",
    "            \"golden rat tail\": \"Golden Pipe Cactus\",\n",
    "            \"cleistocactus\": \"Golden Pipe Cactus\",\n",
    "            \"golden cactus\": \"Golden Pipe Cactus\",\n",
    "            \n",
    "            # Moon Cactus (Grafted)\n",
    "            \"hibotan\": \"Moon Cactus (Grafted)\",\n",
    "            \"grafted cactus\": \"Moon Cactus (Grafted)\",\n",
    "            \"color top\": \"Moon Cactus (Grafted)\",\n",
    "            \n",
    "            # Graptoveria opalina\n",
    "            \"opalina\": \"Graptoveria opalina\",\n",
    "            \"ghost plant\": \"Graptoveria opalina\",\n",
    "            \"pastel succulent\": \"Graptoveria opalina\",\n",
    "            \n",
    "            # Crassula tetragona\n",
    "            \"mini pine tree\": \"Crassula tetragona\",\n",
    "            \"crassula\": \"Crassula tetragona\",\n",
    "            \"tetragona\": \"Crassula tetragona\",\n",
    "            \n",
    "            # Aloe Vera\n",
    "            \"aloe\": \"Aloe Vera\",\n",
    "            \"burn plant\": \"Aloe Vera\",\n",
    "            \"first aid plant\": \"Aloe Vera\",\n",
    "            \n",
    "            # Euphorbia (Red)\n",
    "            \"crown of thorns\": \"Euphorbia (Red)\",\n",
    "            \"red spurge\": \"Euphorbia (Red)\",\n",
    "            \"christ plant\": \"Euphorbia (Red)\",\n",
    "            \n",
    "            # Vermicompost\n",
    "            \"worm compost\": \"Vermicompost\",\n",
    "            \"vermi compost\": \"Vermicompost\",\n",
    "            \"worm castings\": \"Vermicompost\",\n",
    "            \n",
    "            # Vermicompost Mixture\n",
    "            \"vermi mix\": \"Vermicompost Mixture\",\n",
    "            \"worm mix\": \"Vermicompost Mixture\",\n",
    "            \"organic compost\": \"Vermicompost Mixture\",\n",
    "            \n",
    "            # Dec-Neemo (Bio-fertilizer)\n",
    "            \"neem fertilizer\": \"Dec-Neemo (Bio-fertilizer)\",\n",
    "            \"neem cake\": \"Dec-Neemo (Bio-fertilizer)\",\n",
    "            \"organic neem\": \"Dec-Neemo (Bio-fertilizer)\",\n",
    "            \n",
    "            # Dec-Mori (Bio-fertilizer)\n",
    "            \"seaweed fertilizer\": \"Dec-Mori (Bio-fertilizer)\",\n",
    "            \"mori organic\": \"Dec-Mori (Bio-fertilizer)\",\n",
    "            \"bio seaweed\": \"Dec-Mori (Bio-fertilizer)\",\n",
    "            \n",
    "            # Agni Shield\n",
    "            \"plant protector\": \"Agni Shield\",\n",
    "            \"disease shield\": \"Agni Shield\",\n",
    "            \"plant guard\": \"Agni Shield\"\n",
    "        }\n",
    "\n",
    "\n",
    "    def _match_product_name(self, user_input):\n",
    "        \"\"\"Fuzzy match product names with fallback to aliases\"\"\"\n",
    "        # Try direct alias match first\n",
    "        lower_input = user_input.lower()\n",
    "        for alias, canonical in self.product_aliases.items():\n",
    "            if alias in lower_input:\n",
    "                return canonical\n",
    "        \n",
    "        # Fuzzy match with product names\n",
    "        matches = process.extract(\n",
    "            user_input,\n",
    "            self.product_names,\n",
    "            scorer=fuzz.token_sort_ratio,\n",
    "            limit=3\n",
    "        )\n",
    "        \n",
    "        # Return best match above 80% threshold\n",
    "        if matches and matches[0][1] > 80:\n",
    "            return matches[0][0]\n",
    "        return None\n",
    "\n",
    "\n",
    "    def get_response(self, messages):\n",
    "        state = self._get_last_order_state(messages)\n",
    "        \n",
    "        # Force order flow continuity\n",
    "        if state.get(\"step_number\", 1) > 1:\n",
    "            return self._continue_order_flow(messages, state)\n",
    "            \n",
    "        # Detect product names even in casual phrases\n",
    "        user_input = messages[-1]['content']\n",
    "        product_match = self._match_product_name(user_input)\n",
    "        \n",
    "        if product_match:\n",
    "            return self._initiate_order(product_match)\n",
    "            \n",
    "        # Explicitly ask for clarification\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Which plant would you like to order? Here are our products: [list]\",\n",
    "            \"memory\": {\"agent\": \"order_taking_agent\"}\n",
    "        }\n",
    "    \n",
    "    def _continue_order_flow(self, messages, state):\n",
    "        if state[\"step_number\"] == 2:\n",
    "            return self._process_quantity(messages[-1]['content'], state)\n",
    "        if state[\"step_number\"] == 3:\n",
    "            return self._confirm_order(state)\n",
    "        return self._error_response(\"Invalid order state\")\n",
    "    \n",
    "    def _initiate_order(self, product_name):\n",
    "        product = next(p for p in self.products if p[\"name\"] == product_name)\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Great choice! How many {product_name} would you like?\",\n",
    "            \"memory\": {\n",
    "                \"agent\": \"order_taking_agent\",\n",
    "                \"step_number\": 2,\n",
    "                \"current_item\": product_name,\n",
    "                \"order\": []\n",
    "            }\n",
    "        }\n",
    "\n",
    "    \n",
    "    def _process_quantity(self, user_input, state):\n",
    "        try:\n",
    "            match = re.search(r'\\d+', user_input)\n",
    "            quantity = int(match.group()) if match else 1\n",
    "            product = next(p for p in self.products if p[\"name\"] == state[\"current_item\"])\n",
    "            \n",
    "            new_item = {\n",
    "                \"item\": product[\"name\"],\n",
    "                \"quantity\": quantity,\n",
    "                \"price\": quantity * product[\"price\"]\n",
    "            }\n",
    "            updated_order = state[\"order\"] + [new_item]\n",
    "            \n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"Added {quantity} {product['name']}. Anything else?\",\n",
    "                \"memory\": {\n",
    "                    \"agent\": \"order_taking_agent\",\n",
    "                    \"step_number\": 3,\n",
    "                    \"order\": updated_order\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"Please enter a valid quantity (e.g., '2 plants')\",\n",
    "                \"memory\": state\n",
    "            }\n",
    "    \n",
    "    def _confirm_order(self, state):\n",
    "        total = sum(item[\"price\"] for item in state[\"order\"])\n",
    "        order_summary = \"\\n\".join(\n",
    "            f\"- {item['item']} x{item['quantity']}: ₹{item['price']}\"\n",
    "            for item in state[\"order\"]\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": f\"Your order:\\n{order_summary}\\nTotal: ₹{total}\\nConfirm? (yes/no)\",\n",
    "            \"memory\": {\n",
    "                \"agent\": \"order_taking_agent\",\n",
    "                \"step_number\": 4,\n",
    "                \"order\": state[\"order\"]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "    def _process_order_flow(self, messages):\n",
    "        messages = deepcopy(messages)\n",
    "        product_list = \"\\n\".join(f\"{p['name']} - ₹{p['price']}\" for p in self.products)\n",
    "        \n",
    "        system_prompt = f\"\"\"<<SYS>>\n",
    "You are an order processing bot. Products:\n",
    "{product_list}\n",
    "\n",
    "Follow these steps strictly:\n",
    "1. Identify product(s)\n",
    "2. Confirm quantity\n",
    "3. Review order\n",
    "4. Final confirmation\n",
    "\n",
    "Respond in JSON format:\n",
    "{{\n",
    "    \"step_number\": 1-4,\n",
    "    \"order\": [{{\"item\": \"EXACT_NAME\", \"quantity\": N}}],\n",
    "    \"response\": \"Message to user\"\n",
    "}}\n",
    "<</SYS>>\"\"\"\n",
    "\n",
    "        input_messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": messages[-1]['content']}\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            chatbot_output = get_chatbot_response(\n",
    "                client=self.client,\n",
    "                model_name=self.model_name,\n",
    "                messages=input_messages,\n",
    "                temperature=0.3\n",
    "            )\n",
    "            output = self._clean_output(chatbot_output)\n",
    "            \n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": output.get(\"response\", \"How can I assist with your order?\"),\n",
    "                \"memory\": {\n",
    "                    \"agent\": \"order_taking_agent\",\n",
    "                    \"step_number\": output.get(\"step_number\", 1),\n",
    "                    \"order\": output.get(\"order\", [])\n",
    "                }\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return self._error_response(str(e))\n",
    "\n",
    "    def _get_last_order_state(self, messages):\n",
    "        \"\"\"Extract last order state from conversation history\"\"\"\n",
    "        for message in reversed(messages):\n",
    "            if message.get(\"role\") == \"assistant\":\n",
    "                memory = message.get(\"memory\", {})\n",
    "                if memory.get(\"agent\") == \"order_taking_agent\":\n",
    "                    return {\n",
    "                        \"step\": memory.get(\"step_number\", 1),\n",
    "                        \"order\": memory.get(\"order\", []),\n",
    "                        \"asked_recommendation\": memory.get(\"asked_recommendation_before\", False)\n",
    "                    }\n",
    "        return {\"step\": 1, \"order\": [], \"asked_recommendation\": False}\n",
    "\n",
    "    def _clean_output(self, raw_output):\n",
    "        \"\"\"Ensure valid JSON output structure\"\"\"\n",
    "        try:\n",
    "            # Remove any code blocks\n",
    "            clean_output = raw_output.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            output = json.loads(clean_output)\n",
    "            \n",
    "            # Validate required fields\n",
    "            if not all(k in output for k in [\"step_number\", \"order\", \"response\"]):\n",
    "                raise ValueError(\"Missing required fields\")\n",
    "                \n",
    "            # Ensure order is a list\n",
    "            if isinstance(output[\"order\"], str):\n",
    "                output[\"order\"] = json.loads(output[\"order\"])\n",
    "                \n",
    "            return output\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error cleaning output: {e}\")\n",
    "            return {\n",
    "                \"step_number\": 1,\n",
    "                \"order\": [],\n",
    "                \"response\": \"Sorry, I'm having trouble processing your order. Please try again.\"\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    def _error_response(self, error_msg):\n",
    "        \"\"\"Generate error response\"\"\"\n",
    "        print(f\"OrderTakingAgent error: {error_msg}\")\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Sorry, I'm having trouble with your order. Please try again.\",\n",
    "            \"memory\": {\n",
    "                \"agent\": \"order_taking_agent\",\n",
    "                \"step_number\": 1,\n",
    "                \"order\": [],\n",
    "                \"asked_recommendation_before\": False\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Details Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "from datetime import datetime \n",
    "\n",
    "\n",
    "class DetailsAgent():\n",
    "    def __init__(self):\n",
    "        # Initialize chat model client\n",
    "        self.client = boto3.client(\n",
    "            service_name='bedrock-runtime',\n",
    "            region_name=os.getenv(\"AWS_REGION\", \"us-east-1\")\n",
    "        )\n",
    "        self.chat_model_id = os.getenv(\"BEDROCK_MODEL_NAME\", \"mistral.mistral-7b-instruct-v0:2\")\n",
    "        \n",
    "        # Load knowledge documents directly\n",
    "        self.knowledge_base = self._load_knowledge_documents(\n",
    "            documents={\n",
    "                \"about_us\": r\"A:\\NLP Projects\\Chatbot\\python_code\\Experiments\\Plantify_about_us.txt\",\n",
    "                \"price_list\": r\"A:\\NLP Projects\\Chatbot\\python_code\\Experiments\\price_list_text.txt\"\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def _load_knowledge_documents(self, documents):\n",
    "        \"\"\"Load and validate knowledge documents\"\"\"\n",
    "        knowledge = {}\n",
    "        try:\n",
    "            for doc_name, doc_path in documents.items():\n",
    "                if not os.path.exists(doc_path):\n",
    "                    raise FileNotFoundError(f\"Document not found: {doc_path}\")\n",
    "                \n",
    "                with open(doc_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read().strip()\n",
    "                \n",
    "                if not content:\n",
    "                    raise ValueError(f\"Empty document: {doc_path}\")\n",
    "                \n",
    "                knowledge[doc_name] = {\n",
    "                    \"content\": content,\n",
    "                    \"path\": doc_path,\n",
    "                    \"last_modified\": os.path.getmtime(doc_path)\n",
    "                }\n",
    "            \n",
    "            print(\"Loaded knowledge documents:\")\n",
    "            for doc_name, data in knowledge.items():\n",
    "                print(f\"- {doc_name}: {len(data['content'])} chars, last modified {datetime.fromtimestamp(data['last_modified'])}\")\n",
    "            \n",
    "            return knowledge\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to load knowledge base: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _select_relevant_documents(self, user_message):\n",
    "        \"\"\"Determine which documents are relevant to the query\"\"\"\n",
    "        query_lower = user_message.lower()\n",
    "        relevant_docs = []\n",
    "        \n",
    "        # Simple keyword-based routing\n",
    "        if any(word in query_lower for word in [\"price\", \"cost\", \"how much\"]):\n",
    "            relevant_docs.append(\"price_list\")\n",
    "        \n",
    "        if any(word in query_lower for word in [\"store\", \"location\", \"hour\", \"deliver\", \"about\"]):\n",
    "            relevant_docs.append(\"about_us\")\n",
    "        \n",
    "        # If no specific match, use all documents\n",
    "        return relevant_docs if relevant_docs else list(self.knowledge_base.keys())\n",
    "\n",
    "    def get_response(self, messages):\n",
    "        user_message = messages[-1]['content']\n",
    "        \n",
    "        try:\n",
    "            # Select relevant documents\n",
    "            relevant_docs = self._select_relevant_documents(user_message)\n",
    "            print(f\"Selected documents: {relevant_docs}\")\n",
    "            \n",
    "            # Prepare context with document boundaries\n",
    "            context = []\n",
    "            for doc_name in relevant_docs:\n",
    "                doc_data = self.knowledge_base[doc_name]\n",
    "                context.append(\n",
    "                    f\"===== {doc_name.upper().replace('_', ' ')} =====\\n\"\n",
    "                    f\"{doc_data['content']}\\n\"\n",
    "                )\n",
    "            \n",
    "            prompt = f\"\"\"<<SYS>>\n",
    "You are a precise Plantify store assistant. Use ONLY the following documents to answer.\n",
    "If the information isn't present, respond: \"This information isn't available in our records. Please visit www.plantify.com for details.\"\n",
    "\n",
    "DOCUMENTS:\n",
    "{\"\".join(context)}\n",
    "<</SYS>>\n",
    "\n",
    "Question: {user_message}\n",
    "\n",
    "Answer concisely and accurately:\"\"\"\n",
    "            \n",
    "            # Get response with supported parameters only\n",
    "            response = get_chatbot_response(\n",
    "                client=self.client,\n",
    "                model_name=self.chat_model_id,\n",
    "                messages=[{\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }],\n",
    "                temperature=0.1,\n",
    "                max_tokens=300\n",
    "                # Removed the unsupported top_p parameter\n",
    "            )\n",
    "            \n",
    "            # Post-process response\n",
    "            response = response.strip()\n",
    "            if not response or any(phrase in response.lower() for phrase in [\"i don't know\", \"not available\"]):\n",
    "                response = \"This information isn't available in our records. Please visit www.plantify.com for details.\"\n",
    "            \n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": response,\n",
    "                \"memory\": {\n",
    "                    \"agent\": \"details_agent\",\n",
    "                    \"sources\": relevant_docs,\n",
    "                    \"documents_used\": len(relevant_docs)\n",
    "                }\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error in DetailsAgent: {e}\")\n",
    "            return {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": \"I'm experiencing technical difficulties. Please try again later or contact support.\",\n",
    "                \"memory\": {\n",
    "                    \"agent\": \"details_agent\",\n",
    "                    \"error\": str(e)\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        \n",
    "    def postprocess(self, output):\n",
    "        \"\"\"Maintain compatibility with existing code\"\"\"\n",
    "        if isinstance(output, dict):\n",
    "            return output\n",
    "        return {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": output,\n",
    "            \"memory\": {\"agent\": \"details_agent\"}\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Full Agent Testing Mode ===\n",
      "Type 'exit' to quit\n",
      "\n",
      "Loaded knowledge documents:\n",
      "- about_us: 2805 chars, last modified 2025-04-01 03:56:48.411321\n",
      "- price_list: 1063 chars, last modified 2025-04-03 21:19:11.508162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Guard Agent Analysis]\n",
      "Decision: allowed\n",
      "Response: Great! Which type of rose would you like to order? We have a variety of roses available.\n",
      "Reasoning: The user is asking to make an order, which is allowed.\n",
      "\n",
      "[Classification Agent Analysis]\n",
      "Selected Agent: order_taking_agent\n",
      "\n",
      "[Routing to Order Taking Agent]\n",
      "\n",
      "[Agent Response]\n",
      "Response: Which plant would you like to order? Here are our products: [list]\n",
      "\n",
      "\n",
      "[Guard Agent Analysis]\n",
      "Decision: allowed\n",
      "Response: Great choice! Our rose plant is beautiful and fragrant. I'll connect you with our order_taking_agent to help you place your order. Do you have a preferred variety or size?\n",
      "Reasoning: User is asking about making an order, specifically for a rose plant. This is allowed.\n",
      "\n",
      "[Classification Agent Analysis]\n",
      "Selected Agent: order_taking_agent\n",
      "\n",
      "[Routing to Order Taking Agent]\n",
      "\n",
      "[Agent Response]\n",
      "Response: Which plant would you like to order? Here are our products: [list]\n",
      "\n",
      "\n",
      "[Guard Agent Analysis]\n",
      "Decision: allowed\n",
      "Response: Great choice! Could you please specify the quantity and any additional details, such as a delivery address or preferred delivery date?\n",
      "Reasoning: User is asking about a specific plant and intending to make a purchase. This is a valid request.\n",
      "\n",
      "[Classification Agent Analysis]\n",
      "Selected Agent: order_taking_agent\n",
      "\n",
      "[Routing to Order Taking Agent]\n",
      "\n",
      "[Agent Response]\n",
      "Response: Which plant would you like to order? Here are our products: [list]\n",
      "\n",
      "\n",
      "[Guard Agent Analysis]\n",
      "Decision: allowed\n",
      "Response: Sure! Could you please specify which plant you'd like to order and the quantity? Here are our available plants: [list]\n",
      "Reasoning: The user is asking about making an order, which is allowed.\n",
      "\n",
      "[Classification Agent Analysis]\n",
      "Selected Agent: order_taking_agent\n",
      "\n",
      "[Routing to Order Taking Agent]\n",
      "\n",
      "[Agent Response]\n",
      "Response: Which plant would you like to order? Here are our products: [list]\n",
      "\n",
      "\n",
      "Exiting test mode...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "def test_full_agent_flow():\n",
    "    \"\"\"Test the complete agent flow (Guard → Classification → Specific Agent)\"\"\"\n",
    "    print(\"=== Full Agent Testing Mode ===\")\n",
    "    print(\"Type 'exit' to quit\\n\")\n",
    "    \n",
    "    # Initialize all agents\n",
    "    guard = GuardAgent()\n",
    "    classifier = ClassificationAgent()\n",
    "    details_agent = DetailsAgent()\n",
    "    order_taking_agent = OrderTakingAgent()\n",
    "    \n",
    "    conversation_history = []\n",
    "    order_complete = False\n",
    "    \n",
    "    while True:\n",
    "        if order_complete:\n",
    "            print(\"\\n[Order Complete] Thank you for ordering from Plantify! Your order has been confirmed.\")\n",
    "            break\n",
    "            \n",
    "        # Get user input\n",
    "        user_input = input(\"You: \").strip().lower()\n",
    "        \n",
    "        if user_input in ('exit', 'quit'):\n",
    "            print(\"\\nExiting test mode...\")\n",
    "            break\n",
    "            \n",
    "        if not user_input:\n",
    "            continue\n",
    "            \n",
    "        # Check for order completion phrases\n",
    "        if any(phrase in user_input for phrase in [\"no that's all\", \"no thanks\", \"nothing else\", \"that's it\"]):\n",
    "            order_complete = True\n",
    "            continue\n",
    "            \n",
    "        # Add to conversation history\n",
    "        conversation_history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_input\n",
    "        })\n",
    "        \n",
    "        # 1. First, get guard agent's response\n",
    "        guard_response = guard.get_response(conversation_history)\n",
    "        \n",
    "        # Display guard agent analysis\n",
    "        print(\"\\n[Guard Agent Analysis]\")\n",
    "        print(f\"Decision: {guard_response['memory']['guard_decision']}\")\n",
    "        print(f\"Response: {guard_response['content']}\")\n",
    "        if \"chain_of_thought\" in guard_response.get(\"memory\", {}):\n",
    "            print(f\"Reasoning: {guard_response['memory']['chain_of_thought']}\")\n",
    "        \n",
    "        # Only proceed if allowed by guard\n",
    "        if guard_response['memory']['guard_decision'] == \"allowed\":\n",
    "            # 2. Get classification agent's response\n",
    "            classification_response = classifier.get_response(conversation_history)\n",
    "            \n",
    "            # Display classification results\n",
    "            print(\"\\n[Classification Agent Analysis]\")\n",
    "            print(f\"Selected Agent: {classification_response['memory']['classification_decision']}\")\n",
    "            if \"chain_of_thought\" in classification_response.get(\"memory\", {}):\n",
    "                print(f\"Reasoning: {classification_response['memory']['chain_of_thought']}\")\n",
    "            \n",
    "            # 3. Route to the appropriate agent\n",
    "            selected_agent = classification_response['memory']['classification_decision']\n",
    "            agent_response = None\n",
    "            \n",
    "            if selected_agent == \"details_agent\":\n",
    "                print(\"\\n[Routing to Details Agent]\")\n",
    "                agent_response = details_agent.get_response(conversation_history)\n",
    "                \n",
    "            elif selected_agent == \"order_taking_agent\":\n",
    "                print(\"\\n[Routing to Order Taking Agent]\")\n",
    "                agent_response = order_taking_agent.get_response(conversation_history)\n",
    "                \n",
    "                # Check if this is a final confirmation step\n",
    "                if agent_response['memory'].get('step_number', 1) >= 4:  # Assuming step 4 is final confirmation\n",
    "                    order_complete = True\n",
    "                    continue\n",
    "                \n",
    "                # Additional order validation and calculation\n",
    "                if \"order\" in agent_response.get(\"memory\", {}):\n",
    "                    order = agent_response['memory']['order']\n",
    "                    if order:\n",
    "                        total = sum(item.get('price', 0) * item.get('quantity', 1) for item in order)\n",
    "                        print(f\"\\n[Order Calculation]\")\n",
    "                        print(\"Current Order Items:\")\n",
    "                        for item in order:\n",
    "                            print(f\"- {item.get('item', 'Unknown')}: {item.get('quantity', 1)} x ₹{item.get('price', 0)}\")\n",
    "                        print(f\"TOTAL: ₹{total}\")\n",
    "            \n",
    "            else:\n",
    "                agent_response = {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": f\"Agent '{selected_agent}' is not yet implemented\",\n",
    "                    \"memory\": {\"agent\": selected_agent}\n",
    "                }\n",
    "            \n",
    "            # Display final agent response with proper error handling\n",
    "            print(\"\\n[Agent Response]\")\n",
    "            print(f\"Response: {agent_response['content']}\")\n",
    "            \n",
    "            # Safely handle memory fields\n",
    "            memory = agent_response.get(\"memory\", {})\n",
    "            if \"sources\" in memory:\n",
    "                print(f\"Sources: {memory['sources']}\")\n",
    "            if \"scores\" in memory:\n",
    "                print(f\"Confidence Scores: {memory['scores']}\")\n",
    "            if \"error\" in memory:\n",
    "                print(f\"Error Details: {memory['error']}\")\n",
    "            if \"recommended_items\" in memory:\n",
    "                print(f\"Recommended Items: {memory['recommended_items']}\")\n",
    "            if \"recommendation_type\" in memory:\n",
    "                print(f\"Recommendation Type: {memory['recommendation_type']}\")\n",
    "            if \"step_number\" in memory:\n",
    "                print(f\"Order Step: {memory['step_number']}\")\n",
    "            \n",
    "            # Add all responses to history\n",
    "            conversation_history.extend([\n",
    "                guard_response,\n",
    "                classification_response,\n",
    "                agent_response\n",
    "            ])\n",
    "        else:\n",
    "            # Add only guard response to history if not allowed\n",
    "            conversation_history.append(guard_response)\n",
    "        \n",
    "        print()  # Add spacing between turns\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_full_agent_flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agenticchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
